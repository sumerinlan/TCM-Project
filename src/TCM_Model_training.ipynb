{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIS_tuple.txt format: indexes of dis, sym, herb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/HIS_tuple.txt') as dis_dct_file:\n",
    "    lines = dis_dct_file.readlines()\n",
    "lines = [line.strip().split() for line in lines]\n",
    "training = []\n",
    "for line in lines:\n",
    "    if len(line) == 3:\n",
    "        record = [list(map(int, entry.strip()[:-1].split(':'))) for entry in line]\n",
    "        training.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that parses a text file into a dictionary\n",
    "def parse_dict(file_name): \n",
    "    with open('../data/'+file_name) as file:\n",
    "        lines = file.readlines()\n",
    "    lines = [line.strip().split() for line in lines]\n",
    "    dict = {}\n",
    "    for line in lines:\n",
    "        if len(line) == 2:\n",
    "            dict[int(line[1])] = line[0]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_dict = parse_dict('sym_dct.txt')\n",
    "herb_dict = parse_dict('herb_dct.txt')\n",
    "dis_dict = parse_dict('dis_dct.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of symptoms:  15070\n",
      "Number of herbs:  848\n",
      "Number of diseases:  1558\n",
      "Number of records:  9486\n"
     ]
    }
   ],
   "source": [
    "num_sym = len(sym_dict)\n",
    "num_herb = len(herb_dict)\n",
    "num_dis = len(dis_dict)\n",
    "num_record = len(training)\n",
    "print(\"Number of symptoms: \", num_sym)\n",
    "print(\"Number of herbs: \", num_herb)\n",
    "print(\"Number of diseases: \", num_dis)\n",
    "print(\"Number of records: \",num_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3040217322"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for record in training:\n",
    "    count += len(record[1])*len(record[2])\n",
    "count*num_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize symptom popularity dictionary\n",
    "sym_dict = {}\n",
    "for i in range(num_sym):\n",
    "    sym_dict[i+1] = 0\n",
    "\n",
    "# Initialize herb popularity dictionary\n",
    "herb_dict = {}\n",
    "for i in range(num_herb):\n",
    "    herb_dict[i+1] = 0\n",
    "    \n",
    "# Initialize disease popularity dictionary\n",
    "dis_dict = {}\n",
    "for i in range(num_dis):\n",
    "    dis_dict[i+1] = 0\n",
    "\n",
    "# Loop through training data to fill in the popularity dictionaries\n",
    "for record in training[:1000]:\n",
    "    for disease in record[0]:\n",
    "        dis_dict[disease] += 1\n",
    "    for symptom in record[1]:\n",
    "        sym_dict[symptom] += 1\n",
    "    for herb in record[2]:\n",
    "        herb_dict[herb] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dis_dict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort each popularity dictionary based on count\n",
    "sym_list = [(k, sym_dict[k]) for k in sorted(sym_dict, key=sym_dict.get, reverse=True)]\n",
    "dis_list = [(k, dis_dict[k]) for k in sorted(dis_dict, key=dis_dict.get, reverse=True)]\n",
    "herb_list = [(k, herb_dict[k]) for k in sorted(herb_dict, key=herb_dict.get, reverse=True)]\n",
    "\n",
    "# Extract the most popular symptoms, herbs, and diseases based on popularity\n",
    "key_sym = []\n",
    "key_herb = []\n",
    "key_dis = []\n",
    "# Get top 500 popular symptoms and herbs\n",
    "for i in range(500):\n",
    "    key_sym.append(sym_list[i][0])\n",
    "    key_herb.append(herb_list[i][0])\n",
    "# Get top 200 popular diseases\n",
    "for i in range(92):\n",
    "    key_dis.append(dis_list[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "985"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the training data, eliminate rare diseases, symptoms, and herbs from the training records\n",
    "key_dis_set = set(key_dis)\n",
    "key_sym_set = set(key_sym)\n",
    "key_dis_set = set(key_dis)\n",
    "\n",
    "key_training = []\n",
    "for record in training[:1000]:\n",
    "    new_dis = [x for x in record[0] if x in key_dis_set]\n",
    "    if len(new_dis) == 0:\n",
    "        continue\n",
    "    new_sym = [x for x in record[1] if x in key_sym_set]\n",
    "    if len(new_sym) == 0:\n",
    "        continue\n",
    "    new_herb = [x for x in record[2] if x in key_dis_set]\n",
    "    if len(new_herb) == 0:\n",
    "        continue\n",
    "    key_training.append([new_dis, new_sym, new_herb])\n",
    "    \n",
    "len(key_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154953"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsh_tuples = []\n",
    "for i in range(len(key_training)):\n",
    "    record = key_training[i]\n",
    "    for symptom in record[1]:\n",
    "        for herb in record[2]:\n",
    "            tsh_tuples.append((i, symptom, herb))\n",
    "len(tsh_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of diseases:  92\n",
      "number of symtom:  500\n",
      "number of herb:  500\n",
      "number of record:  985\n"
     ]
    }
   ],
   "source": [
    "key_num_dis = len(key_dis)\n",
    "key_num_sym = len(key_sym)\n",
    "key_num_herb = len(key_herb)\n",
    "key_num_record = len(key_training)\n",
    "print(\"number of diseases: \", key_num_dis)\n",
    "print(\"number of symtom: \", key_num_sym)\n",
    "print(\"number of herb: \", key_num_herb)\n",
    "print(\"number of record: \", key_num_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM to train the model.\n",
    "At each step, random pick 10 records as the training data,\n",
    "then iterator until model converges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(input_dict):\n",
    "    small_mass = 10**-20\n",
    "    normalizer = 0.0\n",
    "    for key in input_dict.keys():\n",
    "        normalizer += input_dict[key]\n",
    "    normalizer += len(input_dict) * small_mass\n",
    "    for key in input_dict.keys():\n",
    "        input_dict[key] = (input_dict[key] + small_mass) / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "\n",
    "# P(d)\n",
    "P_d = {}\n",
    "for d in key_dis:\n",
    "    P_d[d] = random.randint(1,3)\n",
    "normalizer(P_d)\n",
    "\n",
    "# P(t|d)\n",
    "P_t_d = {}\n",
    "for d in key_dis:\n",
    "    t_dict = {}\n",
    "    for t in range(len(key_training)):\n",
    "        t_dict[t] = random.randint(1,3)\n",
    "    normalizer(t_dict)\n",
    "    P_t_d[d] = t_dict\n",
    "\n",
    "# P(s|d)\n",
    "P_s_d = {}\n",
    "for d in key_dis:\n",
    "    s_dict = {}\n",
    "    for s in key_sym:\n",
    "        s_dict[s] = random.randint(1,3)\n",
    "    normalizer(s_dict)\n",
    "    P_s_d[d] = s_dict\n",
    "\n",
    "# P(h|d)\n",
    "P_h_d = {}\n",
    "for d in key_dis:\n",
    "    h_dict = {}\n",
    "    for h in key_herb:\n",
    "        h_dict[h] = random.randint(1,3)\n",
    "    normalizer(h_dict)\n",
    "    P_h_d[d] = h_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.031275372017866e-05\n",
      "8.407273167544173e-05\n",
      "8.26769563180424e-05\n",
      "9.736791586057239e-05\n",
      "7.604311895236839e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # Compute P(d|s,h,t)\n",
    "    # Declare a small number added to each entry to prevent 0 probability\n",
    "    P_d_sht = {}\n",
    "    for i in range(len(tsh_tuples)):\n",
    "        (t,s,h) = tsh_tuples[i]\n",
    "        prob_list = {}\n",
    "        for d in key_dis:\n",
    "            prob_list[d] = P_d[d] * P_t_d[d][t] * P_s_d[d][s] * P_h_d[d][h]\n",
    "        normalizer(prob_list)\n",
    "        P_d_sht[(t,s,h)] = prob_list\n",
    "\n",
    "    old_P_d = np.asarray(list(P_d.values()))\n",
    "\n",
    "    # Clear out the old distributions from the last iteration\n",
    "    P_d = dict.fromkeys(P_d, 0.0)\n",
    "    for d in key_dis:\n",
    "        P_t_d[d] = dict.fromkeys(P_t_d[d], 0)\n",
    "        P_s_d[d] = dict.fromkeys(P_s_d[d], 0)\n",
    "        P_h_d[d] = dict.fromkeys(P_h_d[d], 0)\n",
    "    # Perform the M step\n",
    "    for (t,s,h) in P_d_sht.keys():\n",
    "        d_dict = P_d_sht[(t,s,h)]\n",
    "        for d in d_dict.keys():\n",
    "            # update P(d)\n",
    "            P_d[d] += d_dict[d]\n",
    "            # update P(t|d)\n",
    "            P_t_d[d][t] += d_dict[d]\n",
    "            # update P_s_d\n",
    "            P_s_d[d][s] += d_dict[d]\n",
    "            # update P_h_d\n",
    "            P_h_d[d][h] += d_dict[d]\n",
    "\n",
    "    # Normalize the new distribution\n",
    "    normalizer(P_d)\n",
    "    for d in key_dis:\n",
    "        normalizer(P_t_d[d])\n",
    "        normalizer(P_s_d[d])\n",
    "        normalizer(P_h_d[d])\n",
    "\n",
    "    new_P_d = np.asarray(list(P_d.values()))\n",
    "    print(np.abs(old_P_d - new_P_d).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle file for further usage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( P_d, open( \"../training_result/P_d.p\", \"wb\" ) )\n",
    "pickle.dump( P_t_d, open( \"../training_result/P_t_d.p\", \"wb\" ) )\n",
    "pickle.dump( P_s_d, open( \"../training_result/P_s_d.p\", \"wb\" ) )\n",
    "pickle.dump( P_h_d, open( \"../training_result/P_h_d.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(key_dis, open(\"../training_result/key_dis\", \"wb\"))\n",
    "pickle.dump(key_sym, open(\"../training_result/key_sym\", \"wb\"))\n",
    "pickle.dump(key_herb, open(\"../training_result/key_herb\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
